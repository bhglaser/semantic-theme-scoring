{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Intangible Investment from 10-K Filings\n",
    "\n",
    "This notebook walks through the full n-gram pipeline applied to SEC 10-K filings.\n",
    "\n",
    "**Research question:** What fraction of a firm's SG&A spending goes toward intangible investment (R&D, brand capital, organizational capital) versus routine operating expenses?\n",
    "\n",
    "**Approach:** Extract noun phrases from 10-K filings, cluster them into semantic communities, hand-label those communities as types of intangible investment, then score each filing against the labeled taxonomy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Make sure you've installed dependencies:\n",
    "```bash\n",
    "pip install -r ../../requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')  # Move to ngram_pipeline root\n",
    "print('Working directory:', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Text Extraction\n",
    "\n",
    "This stage reads raw 10-K files, strips HTML tags, and extracts the Item 7 (MD&A) section using configurable regex patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python 01_extract_text.py --config examples/intangible_investment/config_intangible.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what was extracted\n",
    "import glob\n",
    "texts = glob.glob('output/intangible_investment/texts/*.txt')\n",
    "print(f'{len(texts)} text files extracted')\n",
    "if texts:\n",
    "    with open(texts[0]) as f:\n",
    "        content = f.read()\n",
    "    print(f'\\nFirst file: {os.path.basename(texts[0])}')\n",
    "    print(f'Length: {len(content.split())} words')\n",
    "    print(f'Preview: {content[:500]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Stage 1b: LLM-Based Text Extraction\n\nThe paper uses an LLM to extract SG&A-focused text from each document's Item 7 section before building the n-gram dictionary. For each document, the LLM extracts three types of quotes:\n- **Definition quotes** — what costs make up the expense\n- **Business driver quotes** — why the company incurs these costs\n- **Change driver quotes** — what caused the expense to increase/decrease\n\nThis focuses the dictionary on expense-relevant language rather than all text in the filing.\n\n**Requirements:** Either [Ollama](https://ollama.ai) running locally (free) or an OpenAI API key. Configure in `config_intangible.yaml` under `llm_extract.provider`.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "!python 01b_llm_extract.py --config examples/intangible_investment/config_intangible.yaml",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Check LLM extracts\nextracts = glob.glob('output/intangible_investment/llm_extracts/*.txt')\nprint(f'{len(extracts)} LLM extract files')\nif extracts:\n    with open(extracts[0]) as f:\n        content = f.read()\n    print(f'\\nFirst file: {os.path.basename(extracts[0])}')\n    print(f'Quotes extracted: {len(content.splitlines())}')\n    print(f'Preview:\\n{content[:500]}...')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Stage 2: N-Gram Clustering\n\nExtracts POS-filtered bigrams/trigrams from the LLM-extracted text (if Stage 1b was run) or full documents, embeds them, and clusters into semantic communities.\n\n**Note:** With a small sample corpus, you'll get fewer communities than the full analysis (which produced ~248 from 10,000 n-grams across thousands of filings)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python 02_cluster_ngrams.py --config examples/intangible_investment/config_intangible.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Look at top n-grams\n",
    "master = pd.read_csv('output/intangible_investment/clusters/ngram_master_list.csv')\n",
    "print(f'Top n-grams: {len(master)}')\n",
    "master.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at discovered communities\n",
    "labels = pd.read_csv('output/intangible_investment/clusters/community_results/community_labels_k500.csv')\n",
    "print(f'Communities discovered: {len(labels)}')\n",
    "labels.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Manual Labeling Step\n\n**This is the key human-in-the-loop step.** After Stage 2, you need to open the `community_labels_k500.csv` output and label each community. The `representatives` column shows the most central n-grams — use these to decide what category each community represents.\n\nAdd two columns to the CSV:\n- **`category`**: e.g., `Intangible investment`, `Not intangible investment`, `unknown`\n- **`subcategory`** (optional): e.g., `knowledge capital`, `brand or customer capital`, `organization capital`\n\nFor example:\n- `advertising promotion expense, advertising expense cost` → **Intangible investment / brand or customer capital**\n- `function research development, research development work` → **Intangible investment / knowledge capital**\n- `cost office rent, rent expense office` → **Not intangible investment**\n\nAfter labeling, save the file and set `doc_ngrams.community_labels_csv` in `config_intangible.yaml` to point to it.\n\nA reference file showing what completed labeling looks like (from the full-corpus analysis with ~231 communities) is at `examples/intangible_investment/labeled_communities_reference.csv`.\n\n**Note:** The communities you get from this small sample corpus will differ from the reference — that's expected. The reference is just to show the labeling format."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Look at the reference labeled communities (from the full-corpus analysis)\nlabeled = pd.read_csv('examples/intangible_investment/labeled_communities_reference.csv')\nprint(f'Reference labeled communities: {len(labeled)}')\nprint(f'\\nCategory distribution:')\nprint(labeled['category'].value_counts())\nprint(f'\\nSubcategory distribution (within Intangible investment):')\nprint(labeled[labeled['category'] == 'Intangible investment']['subcategory'].value_counts())\nprint(f'\\nThis is what YOUR labeled CSV should look like after the manual step.')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Stage 3: Per-Document N-Gram Extraction\n\nRe-extracts n-grams from each document's **full Item 7 text** (not the LLM extracts) and builds the master mapping from clustering output + labeled communities. This means the scoring uses the complete document text scored against the focused dictionary."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python 03_extract_doc_ngrams.py --config examples/intangible_investment/config_intangible.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the master mapping\n",
    "mapping = pd.read_csv('output/intangible_investment/master_ngram_mapping.csv')\n",
    "print(f'Master mapping: {len(mapping)} n-grams mapped to categories')\n",
    "print(f'\\nCategory breakdown:')\n",
    "print(mapping['category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4: Document Scoring\n",
    "\n",
    "Scores each document against the labeled communities using cosine-weighted n-gram counts, producing probability distributions over categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python 04_score_documents.py --config examples/intangible_investment/config_intangible.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View final scores\n",
    "scores = pd.read_csv('output/intangible_investment/scores/scores_category_prob_embedding.csv')\n",
    "print(f'Documents scored: {len(scores)}')\n",
    "scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subcategory breakdown (within intangible investment)\n",
    "sub_scores = pd.read_csv('output/intangible_investment/scores/scores_subcategory_prob_embedding.csv')\n",
    "sub_scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize score distributions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if len(scores) > 0:\n",
    "    score_cols = [c for c in scores.columns if c != 'doc_id']\n",
    "    means = scores[score_cols].mean()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    means.plot(kind='bar', ax=ax)\n",
    "    ax.set_ylabel('Average probability')\n",
    "    ax.set_title('Average category scores across documents')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapting to Your Own Corpus\n",
    "\n",
    "To apply this pipeline to a different corpus or topic:\n",
    "\n",
    "1. **Replace the input documents** — put your text files in a directory and point `extract.input_dir` to it\n",
    "2. **Adjust the config** — disable section extraction if your documents don't have sections; update `custom_stop_words` for your domain\n",
    "3. **Run Stages 1-2** — this will discover communities specific to your corpus\n",
    "4. **Label the communities** — open the CSV, review representatives, add your own `category` and `subcategory` labels\n",
    "5. **Run Stages 3-4** — score your documents against your taxonomy\n",
    "\n",
    "The pipeline is domain-agnostic. The same algorithms work for news articles, scientific papers, legal documents, or any other text corpus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}